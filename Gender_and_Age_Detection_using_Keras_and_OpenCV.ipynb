{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UC4CvSZ6lZ52"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oWMrMcRwle77"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "fold0 = pd.read_csv(\"fold_frontal_0_data.txt\",sep = \"\\t\" )\n",
    "fold1 = pd.read_csv(\"fold_frontal_1_data.txt\",sep = \"\\t\")\n",
    "fold2 = pd.read_csv(\"fold_frontal_2_data.txt\",sep = \"\\t\")\n",
    "fold3 = pd.read_csv(\"fold_frontal_3_data.txt\",sep = \"\\t\")\n",
    "fold4 = pd.read_csv(\"fold_frontal_4_data.txt\",sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYCy2fWuliB2",
    "outputId": "e31470d2-08ed-4a96-abf4-b8c9527bb6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13560, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13560 entries, 0 to 13559\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             13560 non-null  object\n",
      " 1   original_image      13560 non-null  object\n",
      " 2   face_id             13560 non-null  int64 \n",
      " 3   age                 13560 non-null  object\n",
      " 4   gender              12991 non-null  object\n",
      " 5   x                   13560 non-null  int64 \n",
      " 6   y                   13560 non-null  int64 \n",
      " 7   dx                  13560 non-null  int64 \n",
      " 8   dy                  13560 non-null  int64 \n",
      " 9   tilt_ang            13560 non-null  int64 \n",
      " 10  fiducial_yaw_angle  13560 non-null  int64 \n",
      " 11  fiducial_score      13560 non-null  int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "total_data = pd.concat([fold0, fold1, fold2, fold3, fold4], ignore_index=True)\n",
    "print(total_data.shape)\n",
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WhwVRBpWli27",
    "outputId": "6767f571-28d3-4f51-bcad-06420e2b7676"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10424815813_e94629b1ec_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>11816644924_075c3d8d59_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10424595844_1009c687e4_o.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>(38, 43)</td>\n",
       "      <td>f</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10190308156_5c748ab2da_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                original_image  face_id       age gender     x  \\\n",
       "0  30601258@N03  10424815813_e94629b1ec_o.jpg        2  (25, 32)      m   301   \n",
       "1  30601258@N03  10437979845_5985be4b26_o.jpg        3  (25, 32)      m   752   \n",
       "2  30601258@N03  11816644924_075c3d8d59_o.jpg        2  (25, 32)      m   175   \n",
       "3  30601258@N03  10424595844_1009c687e4_o.jpg        4  (38, 43)      f  1912   \n",
       "4  30601258@N03  10190308156_5c748ab2da_o.jpg        2  (25, 32)      m  1013   \n",
       "\n",
       "      y    dx    dy  tilt_ang  fiducial_yaw_angle  fiducial_score  \n",
       "0   105   640   641         0                   0              94  \n",
       "1  1255   484   485       180                   0              47  \n",
       "2    80   769   768       -75                   0              34  \n",
       "3   905  1224  1224       155                   0              64  \n",
       "4  1039   453   452       -75                   0              59  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "_B76YUvFlkhh",
    "outputId": "b3dd5d64-4715-4fd4-fe7c-6a69c01227ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bar chart\n",
    "gender = ['f','m','u']\n",
    "plt.bar(gender, total_data.gender.value_counts(), align='center', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QEgyM5zs09M",
    "outputId": "3936c63e-d73e-4505-c8ce-a202a4598115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "     -------------------------------------- 438.7/438.7 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (16.0.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.9/895.9 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ahtes\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Installing collected packages: keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, gast\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.9\n",
      "    Uninstalling flatbuffers-23.5.9:\n",
      "      Successfully uninstalled flatbuffers-23.5.9\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.0\n",
      "    Uninstalling protobuf-4.23.0:\n",
      "      Successfully uninstalled protobuf-4.23.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "Successfully installed flatbuffers-2.0 gast-0.4.0 keras-2.9.0 protobuf-3.20.1 tensorboard-data-server-0.6.1 tensorflow-estimator-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.9.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\ahtes\\anaconda3\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TYp_98ZQll98"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "YHUpBqKKlnyj",
    "outputId": "afab9cc9-537a-44f3-867f-565c9464095f"
   },
   "source": [
    "##### path = \"faces/\"+total_data.user_id.loc[0]+\"/coarse_tilt_aligned_face.\"+str(total_data.face_id.loc[0])+\".\"+total_data.original_image.loc[0]\n",
    "img = load_img(path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TU20HrL1lp5w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13560 entries, 0 to 13559\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   age     13560 non-null  object\n",
      " 1   gender  12991 non-null  object\n",
      " 2   x       13560 non-null  int64 \n",
      " 3   y       13560 non-null  int64 \n",
      " 4   dx      13560 non-null  int64 \n",
      " 5   dy      13560 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 635.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(38, 43)</td>\n",
       "      <td>f</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age gender     x     y    dx    dy  \\\n",
       "0  (25, 32)      m   301   105   640   641   \n",
       "1  (25, 32)      m   752  1255   484   485   \n",
       "2  (25, 32)      m   175    80   769   768   \n",
       "3  (38, 43)      f  1912   905  1224  1224   \n",
       "4  (25, 32)      m  1013  1039   453   452   \n",
       "\n",
       "                                            img_path  \n",
       "0  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "1  faces/30601258@N03/coarse_tilt_aligned_face.3....  \n",
       "2  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "3  faces/30601258@N03/coarse_tilt_aligned_face.4....  \n",
       "4  faces/30601258@N03/coarse_tilt_aligned_face.2....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_data = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()\n",
    "imp_data.info()\n",
    "\n",
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = \"faces/\"+row[1].user_id+\"/coarse_tilt_aligned_face.\"+str(row[1].face_id)+\".\"+row[1].original_image\n",
    "    img_path.append(path)\n",
    "\n",
    "imp_data['img_path'] = img_path\n",
    "imp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KPW3mI_Alrw0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\AppData\\Local\\Temp\\ipykernel_10452\\505261813.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_data.age.loc[idx] = age_mapping_dict[each]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25-32    3543\n",
       "38-43    1911\n",
       "0-2      1837\n",
       "8-13     1694\n",
       "4-6      1586\n",
       "15-20    1208\n",
       "48-53     641\n",
       "60+       603\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n",
    "\n",
    "age_mapping_dict = {each[0]: each[1] for each in age_mapping}\n",
    "drop_labels = []\n",
    "for idx, each in enumerate(imp_data.age):\n",
    "    if each == 'None':\n",
    "        drop_labels.append(idx)\n",
    "    else:\n",
    "        imp_data.age.loc[idx] = age_mapping_dict[each]\n",
    "\n",
    "imp_data = imp_data.drop(labels=drop_labels, axis=0) #droped None values\n",
    "imp_data.age.value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5iKYhb-7luZA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12226 entries, 0 to 13557\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   age       12226 non-null  object\n",
      " 1   gender    12173 non-null  object\n",
      " 2   x         12226 non-null  int64 \n",
      " 3   y         12226 non-null  int64 \n",
      " 4   dx        12226 non-null  int64 \n",
      " 5   dy        12226 non-null  int64 \n",
      " 6   img_path  12226 non-null  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 764.1+ KB\n"
     ]
    }
   ],
   "source": [
    "mp_data = imp_data.dropna()\n",
    "clean_data = imp_data[imp_data.gender != 'u'].copy()\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    6401\n",
       "m    5772\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12226 entries, 0 to 13557\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   age       12226 non-null  object\n",
      " 1   gender    12173 non-null  object\n",
      " 2   x         12226 non-null  int64 \n",
      " 3   y         12226 non-null  int64 \n",
      " 4   dx        12226 non-null  int64 \n",
      " 5   dy        12226 non-null  int64 \n",
      " 6   img_path  12226 non-null  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 764.1+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=clean_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38-43</td>\n",
       "      <td>f</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12168</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>741</td>\n",
       "      <td>769</td>\n",
       "      <td>faces/101515718@N03/coarse_tilt_aligned_face.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12169</th>\n",
       "      <td>25-32</td>\n",
       "      <td>f</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "      <td>656</td>\n",
       "      <td>574</td>\n",
       "      <td>faces/101515718@N03/coarse_tilt_aligned_face.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12170</th>\n",
       "      <td>25-32</td>\n",
       "      <td>f</td>\n",
       "      <td>718</td>\n",
       "      <td>748</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>faces/101515718@N03/coarse_tilt_aligned_face.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12171</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>48</td>\n",
       "      <td>472</td>\n",
       "      <td>768</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/101515718@N03/coarse_tilt_aligned_face.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>25-32</td>\n",
       "      <td>f</td>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>692</td>\n",
       "      <td>687</td>\n",
       "      <td>faces/101515718@N03/coarse_tilt_aligned_face.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12173 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender     x     y    dx    dy  \\\n",
       "0      25-32      m   301   105   640   641   \n",
       "1      25-32      m   752  1255   484   485   \n",
       "2      25-32      m   175    80   769   768   \n",
       "3      38-43      f  1912   905  1224  1224   \n",
       "4      25-32      m  1013  1039   453   452   \n",
       "...      ...    ...   ...   ...   ...   ...   \n",
       "12168  25-32      m     0   404   741   769   \n",
       "12169  25-32      f   838     0   656   574   \n",
       "12170  25-32      f   718   748   492   492   \n",
       "12171  25-32      m    48   472   768   768   \n",
       "12172  25-32      f   950     0   692   687   \n",
       "\n",
       "                                                img_path  \n",
       "0      faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "1      faces/30601258@N03/coarse_tilt_aligned_face.3....  \n",
       "2      faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "3      faces/30601258@N03/coarse_tilt_aligned_face.4....  \n",
       "4      faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "...                                                  ...  \n",
       "12168  faces/101515718@N03/coarse_tilt_aligned_face.2...  \n",
       "12169  faces/101515718@N03/coarse_tilt_aligned_face.2...  \n",
       "12170  faces/101515718@N03/coarse_tilt_aligned_face.2...  \n",
       "12171  faces/101515718@N03/coarse_tilt_aligned_face.2...  \n",
       "12172  faces/101515718@N03/coarse_tilt_aligned_face.2...  \n",
       "\n",
       "[12173 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38-43</td>\n",
       "      <td>f</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age gender     x     y    dx    dy  \\\n",
       "0  25-32      m   301   105   640   641   \n",
       "1  25-32      m   752  1255   484   485   \n",
       "2  25-32      m   175    80   769   768   \n",
       "3  38-43      f  1912   905  1224  1224   \n",
       "4  25-32      m  1013  1039   453   452   \n",
       "\n",
       "                                            img_path  \n",
       "0  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "1  faces/30601258@N03/coarse_tilt_aligned_face.3....  \n",
       "2  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "3  faces/30601258@N03/coarse_tilt_aligned_face.4....  \n",
       "4  faces/30601258@N03/coarse_tilt_aligned_face.2....  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cyh_0yLylvyE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-32</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-32</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-32</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38-43</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-32</td>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender     x     y    dx    dy  \\\n",
       "0  25-32       1   301   105   640   641   \n",
       "1  25-32       1   752  1255   484   485   \n",
       "2  25-32       1   175    80   769   768   \n",
       "3  38-43       0  1912   905  1224  1224   \n",
       "4  25-32       1  1013  1039   453   452   \n",
       "\n",
       "                                            img_path  \n",
       "0  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "1  faces/30601258@N03/coarse_tilt_aligned_face.3....  \n",
       "2  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "3  faces/30601258@N03/coarse_tilt_aligned_face.4....  \n",
       "4  faces/30601258@N03/coarse_tilt_aligned_face.2....  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_to_label_map = {'f' : 0,'m' : 1}\n",
    "\n",
    "clean_data['gender'] = clean_data['gender'].apply(lambda g: gender_to_label_map[g])\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tAixi-RmlxVH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "      <td>905</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>1039</td>\n",
       "      <td>453</td>\n",
       "      <td>452</td>\n",
       "      <td>faces/30601258@N03/coarse_tilt_aligned_face.2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender     x     y    dx    dy  \\\n",
       "0    4       1   301   105   640   641   \n",
       "1    4       1   752  1255   484   485   \n",
       "2    4       1   175    80   769   768   \n",
       "3    5       0  1912   905  1224  1224   \n",
       "4    4       1  1013  1039   453   452   \n",
       "\n",
       "                                            img_path  \n",
       "0  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "1  faces/30601258@N03/coarse_tilt_aligned_face.3....  \n",
       "2  faces/30601258@N03/coarse_tilt_aligned_face.2....  \n",
       "3  faces/30601258@N03/coarse_tilt_aligned_face.4....  \n",
       "4  faces/30601258@N03/coarse_tilt_aligned_face.2....  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_to_label_map = {\n",
    "    '0-2'  :0,\n",
    "    '4-6'  :1,\n",
    "    '8-13' :2,\n",
    "    '15-20':3,\n",
    "    '25-32':4,\n",
    "    '38-43':5,\n",
    "    '48-53':6,\n",
    "    '60+'  :7\n",
    "}\n",
    "\n",
    "clean_data['age'] = clean_data['age'].apply(lambda age: age_to_label_map[age])\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "t30OO0hJlzKW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (8521, 1)\n",
      "Test data shape (3652, 1)\n",
      "Train images shape (8521, 227, 227, 3)\n",
      "Test images shape (3652, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "X = clean_data[['img_path']]\n",
    "y = clean_data[['gender']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))   # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))  # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "GHtMzEm7l10L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 56, 56, 96)        14208     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 28, 28, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, 28, 28, 96)       192       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, 14, 14, 256)      512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  (None, 7, 7, 256)        512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               6423040   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,906,882\n",
      "Trainable params: 7,906,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qz7-su9Al33W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.5200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 264s 982ms/step - loss: 1.0026 - accuracy: 0.5200 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 261s 979ms/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 247s 925ms/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6924 - val_accuracy: 0.5208\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 250s 936ms/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6927 - val_accuracy: 0.5208\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 270s 1s/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 269s 1s/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 291s 1s/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 282s 1s/step - loss: 0.6917 - accuracy: 0.5280 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 295s 1s/step - loss: 0.6918 - accuracy: 0.5280 - val_loss: 0.6925 - val_accuracy: 0.5208\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_images, y_train, batch_size=32, epochs=25, validation_data=(test_images, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "model.save('gender_model25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "qKyRCPSNl566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (8521, 1)\n",
      "Test data shape (3652, 1)\n",
      "Train images shape (8521, 227, 227, 3)\n",
      "Test images shape (3652, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "X = clean_data[['img_path']]\n",
    "y = clean_data[['age']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))   # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))  # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "avy0VM7ll8XF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 96)        14208     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 28, 28, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_3 (Laye  (None, 28, 28, 96)       192       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_4 (Laye  (None, 14, 14, 256)      512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 7, 7, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer_normalization_5 (Laye  (None, 7, 7, 256)        512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               6423040   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,909,960\n",
      "Trainable params: 7,909,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "GnSkGk5Tl-zT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - ETA: 0s - loss: 2.2701 - accuracy: 0.2676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahtes\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 242s 903ms/step - loss: 2.2701 - accuracy: 0.2676 - val_loss: 1.9326 - val_accuracy: 0.2905\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 235s 882ms/step - loss: 1.9335 - accuracy: 0.2865 - val_loss: 1.9300 - val_accuracy: 0.2905\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 223s 837ms/step - loss: 1.9335 - accuracy: 0.2865 - val_loss: 1.9298 - val_accuracy: 0.2905\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 222s 833ms/step - loss: 1.9339 - accuracy: 0.2865 - val_loss: 1.9296 - val_accuracy: 0.2905\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 226s 847ms/step - loss: 1.9335 - accuracy: 0.2865 - val_loss: 1.9302 - val_accuracy: 0.2905\n",
      "115/115 - 25s - loss: 1.9302 - accuracy: 0.2905 - 25s/epoch - 218ms/step\n",
      "0.29052573442459106\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_images, y_train, batch_size=32, epochs=50, validation_data=(test_images, y_test), callbacks=[callback])\n",
    "\n",
    "model.save('age_model50.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBd7dtAHmUKI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
